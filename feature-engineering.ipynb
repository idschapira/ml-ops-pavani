{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rchavarria3007/ml-ops-pavani/blob/main/feature-engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# CÉLULA 1: Instalação de Bibliotecas\n",
        "# ==============================================================================\n",
        "!pip install category_encoders\n",
        "print(\"Biblioteca 'category_encoders' instalada.\")"
      ],
      "metadata": {
        "id": "GZtL2Phf_Hyz",
        "outputId": "5d5f7d19-32f2-43d4-aff3-024a99cd8acd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.8.1-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.15.3)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "Downloading category_encoders-2.8.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.8.1\n",
            "Biblioteca 'category_encoders' instalada.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==============================================================================\n",
        "# Setup e Carregamento de Dados\n",
        "# ==============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import PolynomialFeatures, LabelEncoder\n",
        "import category_encoders as ce\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# Configuração para exibir todas as colunas do pandas\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Carregamento do dataset\n",
        "try:\n",
        "    file_name = \"/content/drive/MyDrive/dev/datascienceexp/bz_hr_attr_features.csv\"\n",
        "    bz_hr_attr_features = pd.read_csv(file_name)\n",
        "    print(f\"\\nDataset '{file_name}' carregado com sucesso!\")\n",
        "    print(\"Dimensões do dataset:\", bz_hr_attr_features.head())\n",
        "except StopIteration:\n",
        "    print(\"\\nNenhum arquivo foi enviado.\")\n",
        "    bz_hr_attr_features = None\n",
        "except Exception as e:\n",
        "    print(f\"Ocorreu um erro ao carregar o arquivo: {e}\")\n",
        "    bz_hr_attr_features = None\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# Criação de Features Base para Transformação\n",
        "# ==============================================================================\n",
        "if bz_hr_attr_features is not None:\n",
        "    print(\"\\n--- Criando Features Base ---\")\n",
        "    # 1. Índice de Burnout\n",
        "    bz_hr_attr_features['OverTime_num'] = bz_hr_attr_features['OverTime'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "    bz_hr_attr_features['IndiceDeBurnout'] = (5 - bz_hr_attr_features['WorkLifeBalance']) + \\\n",
        "      (5 - bz_hr_attr_features['JobSatisfaction']) + \\\n",
        "      bz_hr_attr_features['OverTime_num']\n",
        "\n",
        "    # 2. Índice de Satisfação Geral\n",
        "    bz_hr_attr_features['IndiceDeSatisfacaoGeral'] = (bz_hr_attr_features['JobSatisfaction'] + \\\n",
        "                                                      bz_hr_attr_features['EnvironmentSatisfaction'] + \\\n",
        "                                                      bz_hr_attr_features['RelationshipSatisfaction']) / 3\n",
        "\n",
        "    print(\"Features base 'IndiceDeBurnout' e 'IndiceDeSatisfacaoGeral' criadas.\")\n",
        "    print(bz_hr_attr_features[['IndiceDeBurnout', 'IndiceDeSatisfacaoGeral']].head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 997
        },
        "id": "MlqwsY_8tL_O",
        "outputId": "422978cf-a094-429e-e224-df310fe486a7",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset '/content/drive/MyDrive/dev/datascienceexp/bz_hr_attr_features.csv' carregado com sucesso!\n",
            "Dimensões do dataset:    EmployeeNumber MaritalStatus  JobLevel  JobInvolvement  YearsAtCompany  \\\n",
            "0               1        Single         2               3               6   \n",
            "1               2       Married         2               2              10   \n",
            "2               4        Single         1               2               0   \n",
            "3               5       Married         1               3               8   \n",
            "4               7       Married         1               3               2   \n",
            "\n",
            "   MonthlyIncome  StockOptionLevel  JobSatisfaction  EnvironmentSatisfaction  \\\n",
            "0           5993                 0                4                        2   \n",
            "1           5130                 1                2                        3   \n",
            "2           2090                 0                3                        4   \n",
            "3           2909                 0                3                        4   \n",
            "4           3468                 1                2                        1   \n",
            "\n",
            "  OverTime  WorkLifeBalance Attrition  \n",
            "0      Yes                1       Yes  \n",
            "1       No                3        No  \n",
            "2      Yes                3       Yes  \n",
            "3      Yes                3        No  \n",
            "4       No                3        No  \n",
            "\n",
            "--- Criando Features Base ---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'RelationshipSatisfaction'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'RelationshipSatisfaction'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5-3012421722.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     bz_hr_attr_features['IndiceDeSatisfacaoGeral'] = (bz_hr_attr_features['JobSatisfaction'] + \\\n\u001b[1;32m     41\u001b[0m                                                       \u001b[0mbz_hr_attr_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EnvironmentSatisfaction'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                                                       bz_hr_attr_features['RelationshipSatisfaction']) / 3\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Features base 'IndiceDeBurnout' e 'IndiceDeSatisfacaoGeral' criadas.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'RelationshipSatisfaction'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "----\n",
        "# ==============================================================================\n",
        "# CÉLULA 4: Técnica Avançada 1: Geração de Features Polinomiais\n",
        "# ==============================================================================\n",
        "if df is not None:\n",
        "    print(\"\\n--- Gerando Features Polinomiais ---\")\n",
        "    features_to_transform = ['MonthlyIncome', 'YearsAtCompany', 'IndiceDeBurnout', 'IndiceDeSatisfacaoGeral']\n",
        "    poly_data = df[features_to_transform]\n",
        "\n",
        "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "    poly_features = poly.fit_transform(poly_data)\n",
        "    poly_feature_names = [name.replace(' ', '_X_') for name in poly.get_feature_names_out(features_to_transform)]\n",
        "    df_poly = pd.DataFrame(poly_features, columns=poly_feature_names)\n",
        "\n",
        "    print(\"Novas Features Polinomiais Geradas (amostra):\")\n",
        "    print(df_poly.head())\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# CÉLULA 5: Técnica Avançada 2: Geração de Features com Target Encoding\n",
        "# ==============================================================================\n",
        "if df is not None:\n",
        "    print(\"\\n--- Gerando Features com Target Encoding ---\")\n",
        "    le = LabelEncoder()\n",
        "    df['Attrition_encoded'] = le.fit_transform(df['Attrition'])\n",
        "\n",
        "    categorical_features_to_encode = ['JobRole', 'EducationField', 'MaritalStatus', 'Department']\n",
        "    target_encoder = ce.TargetEncoder(cols=categorical_features_to_encode)\n",
        "    df_target_encoded = target_encoder.fit_transform(df[categorical_features_to_encode], df['Attrition_encoded'])\n",
        "    df_target_encoded = df_target_encoded.rename(columns={col: f'{col}_TargetEncoded' for col in df_target_encoded.columns})\n",
        "\n",
        "    print(\"Novas Features com Target Encoding (amostra):\")\n",
        "    print(df_target_encoded.head())\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# CÉLULA 6: Consolidação e Seleção das 10 Features Avançadas Finais\n",
        "# ==============================================================================\n",
        "if df is not None:\n",
        "    print(\"\\n--- Consolidando e Selecionando as 10 Features Finais ---\")\n",
        "    df_advanced_features = pd.concat([df_poly, df_target_encoded], axis=1)\n",
        "\n",
        "    final_10_features_list = [\n",
        "        # Target Encodings\n",
        "        'JobRole_TargetEncoded',\n",
        "        'MaritalStatus_TargetEncoded',\n",
        "        'EducationField_TargetEncoded',\n",
        "        # Potências\n",
        "        'IndiceDeBurnout^2',\n",
        "        'MonthlyIncome^2',\n",
        "        # Interações\n",
        "        'MonthlyIncome_X_IndiceDeBurnout',\n",
        "        'YearsAtCompany_X_IndiceDeBurnout',\n",
        "        'MonthlyIncome_X_IndiceDeSatisfacaoGeral',\n",
        "        'YearsAtCompany_X_IndiceDeSatisfacaoGeral',\n",
        "        'IndiceDeBurnout_X_IndiceDeSatisfacaoGeral'\n",
        "    ]\n",
        "\n",
        "    df_final_features = df_advanced_features[final_10_features_list]\n",
        "\n",
        "    print(\"\\nDataFrame Final com as 10 Features Avançadas Selecionadas:\")\n",
        "    print(df_final_features.info())\n",
        "    print(\"\\nAmostra das 10 Features Finais:\")\n",
        "    print(df_final_features.head())"
      ],
      "metadata": {
        "id": "YLFxyGX8BQ4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "beD_J_AN_g9b",
        "outputId": "1f38c41f-6175-4fd5-fa65-bb052bda7243",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# CÉLULA 1: Instalação de Bibliotecas\n",
        "# ==============================================================================\n",
        "\n",
        "# O '!' no início permite executar comandos do terminal diretamente no notebook.\n",
        "# 'pip install' é o comando para instalar bibliotecas Python.\n",
        "# 'category_encoders' é uma biblioteca que contém métodos de encoding avançados.\n",
        "!pip install category_encoders\n",
        "\n",
        "# Imprime uma mensagem de confirmação para o usuário saber que a instalação terminou.\n",
        "print(\"Biblioteca 'category_encoders' instalada.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# CÉLULA 2: Setup e Carregamento de Dados\n",
        "# ==============================================================================\n",
        "\n",
        "# Importa a biblioteca pandas, essencial para manipulação de dados em tabelas (DataFrames). 'pd' é um apelido padrão.\n",
        "import pandas as pd\n",
        "# Importa a biblioteca numpy, usada para operações numéricas. 'np' é o apelido padrão.\n",
        "import numpy as np\n",
        "# Do scikit-learn, importa a classe PolynomialFeatures para criar features de interação e LabelEncoder para converter texto em números.\n",
        "from sklearn.preprocessing import PolynomialFeatures, LabelEncoder\n",
        "# Importa a biblioteca que acabamos de instalar, dando a ela o apelido 'ce'.\n",
        "import category_encoders as ce\n",
        "# Importa a função 'files' da biblioteca específica do Google Colab para permitir o upload de arquivos.\n",
        "from google.colab import files\n",
        "# Importa a biblioteca 'io' para manipular o arquivo carregado em memória.\n",
        "import io\n",
        "\n",
        "# Configura o pandas para sempre mostrar todas as colunas de um DataFrame, evitando que sejam ocultadas com '...'.\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Imprime uma instrução para o usuário.\n",
        "print(\"Por favor, faça o upload do arquivo 'WA_Fn-UseC_-HR-Employee-Attrition.csv'\")\n",
        "# Esta função do Colab abre uma janela de diálogo no navegador para que o usuário possa selecionar um arquivo.\n",
        "# O arquivo carregado é armazenado na variável 'uploaded'.\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 'try...except' é um bloco de tratamento de erros, para o código não quebrar se algo der errado.\n",
        "try:\n",
        "    # 'uploaded' é um dicionário. 'next(iter(uploaded))' pega o nome do primeiro (e único) arquivo que foi carregado.\n",
        "    file_name = next(iter(uploaded))\n",
        "    # 'uploaded[file_name]' contém os dados brutos (bytes) do arquivo.\n",
        "    # 'io.BytesIO(...)' transforma esses bytes em um objeto que o pandas pode ler como se fosse um arquivo.\n",
        "    # 'pd.read_csv(...)' lê esses dados e os carrega em um DataFrame chamado 'df'.\n",
        "    df = pd.read_csv(io.BytesIO(uploaded[file_name]))\n",
        "\n",
        "    # Imprime uma mensagem de sucesso, incluindo o nome do arquivo carregado.\n",
        "    print(f\"\\nDataset '{file_name}' carregado com sucesso!\")\n",
        "    # Mostra as dimensões do DataFrame (linhas, colunas).\n",
        "    print(\"Dimensões do dataset:\", df.shape)\n",
        "# 'except StopIteration:' trata o erro específico que ocorre se o usuário cancelar o upload.\n",
        "except StopIteration:\n",
        "    print(\"\\nNenhum arquivo foi enviado.\")\n",
        "    # Se nenhum arquivo for carregado, 'df' é definido como 'None' para que as próximas células não tentem usá-lo.\n",
        "    df = None\n",
        "# 'except Exception as e:' captura qualquer outro erro que possa ocorrer durante o processo.\n",
        "except Exception as e:\n",
        "    print(f\"Ocorreu um erro ao carregar o arquivo: {e}\")\n",
        "    df = None\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# CÉLULA 3: Criação de Features Base para Transformação\n",
        "# ==============================================================================\n",
        "\n",
        "# Verifica se o DataFrame 'df' foi carregado corretamente antes de prosseguir.\n",
        "if df is not None:\n",
        "    print(\"\\n--- Criando Features Base ---\")\n",
        "    # Cria uma nova coluna 'OverTime_num' para representar 'OverTime' numericamente.\n",
        "    # '.apply' executa uma função para cada valor da coluna. A função lambda retorna 1 se o valor for 'Yes', e 0 caso contrário.\n",
        "    df['OverTime_num'] = df['OverTime'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "\n",
        "    # Cria a coluna 'IndiceDeBurnout' somando os fatores de risco (escalas invertidas de satisfação + hora extra).\n",
        "    df['IndiceDeBurnout'] = (5 - df['WorkLifeBalance']) + (5 - df['JobSatisfaction']) + df['OverTime_num']\n",
        "\n",
        "    # Cria a coluna 'IndiceDeSatisfacaoGeral' calculando a média das três métricas de satisfação.\n",
        "    df['IndiceDeSatisfacaoGeral'] = (df['JobSatisfaction'] + df['EnvironmentSatisfaction'] + df['RelationshipSatisfaction']) / 3\n",
        "\n",
        "    print(\"Features base 'IndiceDeBurnout' e 'IndiceDeSatisfacaoGeral' criadas.\")\n",
        "    # '.head()' exibe as 5 primeiras linhas das colunas especificadas para verificação.\n",
        "    print(df[['IndiceDeBurnout', 'IndiceDeSatisfacaoGeral']].head())\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# CÉLULA 4: Técnica Avançada 1: Geração de Features Polinomiais\n",
        "# ==============================================================================\n",
        "\n",
        "# Novamente, verifica se o 'df' existe.\n",
        "if df is not None:\n",
        "    print(\"\\n--- Gerando Features Polinomiais ---\")\n",
        "    # Cria uma lista com os nomes das colunas que serão usadas para gerar as features polinomiais.\n",
        "    features_to_transform = ['MonthlyIncome', 'YearsAtCompany', 'IndiceDeBurnout', 'IndiceDeSatisfacaoGeral']\n",
        "    # Cria um novo DataFrame 'poly_data' contendo apenas as colunas da lista acima.\n",
        "    poly_data = df[features_to_transform]\n",
        "\n",
        "    # Instancia (cria um objeto) do transformador PolynomialFeatures.\n",
        "    # 'degree=2' significa que ele criará features até o segundo grau (x², y², x*y).\n",
        "    # 'include_bias=False' evita a criação de uma coluna constante de valor 1.\n",
        "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "\n",
        "    # '.fit_transform()' aplica a transformação polinomial aos dados.\n",
        "    poly_features = poly.fit_transform(poly_data)\n",
        "\n",
        "    # '.get_feature_names_out()' gera os nomes das novas colunas criadas (ex: 'MonthlyIncome^2').\n",
        "    # A list comprehension substitui espaços por '_X_' para nomes mais legíveis.\n",
        "    poly_feature_names = [name.replace(' ', '_X_') for name in poly.get_feature_names_out(features_to_transform)]\n",
        "\n",
        "    # Cria um novo DataFrame 'df_poly' com os dados transformados e os nomes corretos das colunas.\n",
        "    df_poly = pd.DataFrame(poly_features, columns=poly_feature_names)\n",
        "\n",
        "    print(\"Novas Features Polinomiais Geradas (amostra):\")\n",
        "    # Exibe as 5 primeiras linhas do novo DataFrame para ver o resultado.\n",
        "    print(df_poly.head())\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# CÉLULA 5: Técnica Avançada 2: Geração de Features com Target Encoding\n",
        "# ==============================================================================\n",
        "\n",
        "if df is not None:\n",
        "    print(\"\\n--- Gerando Features com Target Encoding ---\")\n",
        "    # Instancia o LabelEncoder, que converte rótulos de texto em números.\n",
        "    le = LabelEncoder()\n",
        "    # Cria a coluna 'Attrition_encoded', convertendo 'No' para 0 e 'Yes' para 1.\n",
        "    df['Attrition_encoded'] = le.fit_transform(df['Attrition'])\n",
        "\n",
        "    # Cria uma lista com os nomes das colunas categóricas que queremos codificar.\n",
        "    categorical_features_to_encode = ['JobRole', 'EducationField', 'MaritalStatus', 'Department']\n",
        "    # Instancia o TargetEncoder, especificando as colunas que ele deve transformar.\n",
        "    target_encoder = ce.TargetEncoder(cols=categorical_features_to_encode)\n",
        "\n",
        "    # Aplica o Target Encoding. Ele usa as colunas categóricas e a coluna alvo ('Attrition_encoded') para calcular o valor de substituição.\n",
        "    df_target_encoded = target_encoder.fit_transform(df[categorical_features_to_encode], df['Attrition_encoded'])\n",
        "\n",
        "    # Renomeia as colunas do novo DataFrame para indicar que elas foram codificadas (ex: 'JobRole' vira 'JobRole_TargetEncoded').\n",
        "    df_target_encoded = df_target_encoded.rename(columns={col: f'{col}_TargetEncoded' for col in df_target_encoded.columns})\n",
        "\n",
        "    print(\"Novas Features com Target Encoding (amostra):\")\n",
        "    # Mostra as 5 primeiras linhas para verificar o resultado da codificação.\n",
        "    print(df_target_encoded.head())\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# CÉLULA 6: Consolidação e Seleção das 10 Features Avançadas Finais\n",
        "# ==============================================================================\n",
        "\n",
        "if df is not None:\n",
        "    print(\"\\n--- Consolidando e Selecionando as 10 Features Finais ---\")\n",
        "    # 'pd.concat' junta os dois DataFrames de features ('df_poly' e 'df_target_encoded') lado a lado.\n",
        "    # 'axis=1' especifica que a junção deve ser feita pelas colunas.\n",
        "    df_advanced_features = pd.concat([df_poly, df_target_encoded], axis=1)\n",
        "\n",
        "    # Cria uma lista final com os nomes das 10 features avançadas que escolhemos para o modelo.\n",
        "    final_10_features_list = [\n",
        "        # Features de Target Encoding\n",
        "        'JobRole_TargetEncoded',\n",
        "        'MaritalStatus_TargetEncoded',\n",
        "        'EducationField_TargetEncoded',\n",
        "        # Features de Potência (capturam efeitos não-lineares)\n",
        "        'IndiceDeBurnout^2',\n",
        "        'MonthlyIncome^2',\n",
        "        # Features de Interação (capturam efeitos combinados)\n",
        "        'MonthlyIncome_X_IndiceDeBurnout',\n",
        "        'YearsAtCompany_X_IndiceDeBurnout',\n",
        "        'MonthlyIncome_X_IndiceDeSatisfacaoGeral',\n",
        "        'YearsAtCompany_X_IndiceDeSatisfacaoGeral',\n",
        "        'IndiceDeBurnout_X_IndiceDeSatisfacaoGeral'\n",
        "    ]\n",
        "\n",
        "    # Cria o DataFrame final, contendo apenas as 10 colunas da lista acima.\n",
        "    df_final_features = df_advanced_features[final_10_features_list]\n",
        "\n",
        "    print(\"\\nDataFrame Final com as 10 Features Avançadas Selecionadas:\")\n",
        "    # '.info()' imprime um resumo do DataFrame: nomes das colunas, contagem de valores não nulos e tipo de dados.\n",
        "    df_final_features.info()\n",
        "\n",
        "    print(\"\\nAmostra das 10 Features Finais:\")\n",
        "    # Exibe as 5 primeiras linhas do DataFrame final.\n",
        "    print(df_final_features.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6kR-L1ZzuMkF",
        "outputId": "d4cf74a8-6271-4719-c991-22a96adaa4a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.11/dist-packages (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.15.3)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "Biblioteca 'category_encoders' instalada.\n",
            "Por favor, faça o upload do arquivo 'WA_Fn-UseC_-HR-Employee-Attrition.csv'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-910f4cab-d2df-43e8-811d-695addffab2d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-910f4cab-d2df-43e8-811d-695addffab2d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving WA_Fn-UseC_-HR-Employee-Attrition.csv to WA_Fn-UseC_-HR-Employee-Attrition (1).csv\n",
            "\n",
            "Dataset 'WA_Fn-UseC_-HR-Employee-Attrition (1).csv' carregado com sucesso!\n",
            "Dimensões do dataset: (1470, 35)\n",
            "\n",
            "--- Criando Features Base ---\n",
            "Features base 'IndiceDeBurnout' e 'IndiceDeSatisfacaoGeral' criadas.\n",
            "   IndiceDeBurnout  IndiceDeSatisfacaoGeral\n",
            "0                6                 2.333333\n",
            "1                5                 3.000000\n",
            "2                5                 3.000000\n",
            "3                5                 3.333333\n",
            "4                5                 2.333333\n",
            "\n",
            "--- Gerando Features Polinomiais ---\n",
            "Novas Features Polinomiais Geradas (amostra):\n",
            "   MonthlyIncome  YearsAtCompany  IndiceDeBurnout  IndiceDeSatisfacaoGeral  \\\n",
            "0         5993.0             6.0              6.0                 2.333333   \n",
            "1         5130.0            10.0              5.0                 3.000000   \n",
            "2         2090.0             0.0              5.0                 3.000000   \n",
            "3         2909.0             8.0              5.0                 3.333333   \n",
            "4         3468.0             2.0              5.0                 2.333333   \n",
            "\n",
            "   MonthlyIncome^2  MonthlyIncome_X_YearsAtCompany  \\\n",
            "0       35916049.0                         35958.0   \n",
            "1       26316900.0                         51300.0   \n",
            "2        4368100.0                             0.0   \n",
            "3        8462281.0                         23272.0   \n",
            "4       12027024.0                          6936.0   \n",
            "\n",
            "   MonthlyIncome_X_IndiceDeBurnout  MonthlyIncome_X_IndiceDeSatisfacaoGeral  \\\n",
            "0                          35958.0                             13983.666667   \n",
            "1                          25650.0                             15390.000000   \n",
            "2                          10450.0                              6270.000000   \n",
            "3                          14545.0                              9696.666667   \n",
            "4                          17340.0                              8092.000000   \n",
            "\n",
            "   YearsAtCompany^2  YearsAtCompany_X_IndiceDeBurnout  \\\n",
            "0              36.0                              36.0   \n",
            "1             100.0                              50.0   \n",
            "2               0.0                               0.0   \n",
            "3              64.0                              40.0   \n",
            "4               4.0                              10.0   \n",
            "\n",
            "   YearsAtCompany_X_IndiceDeSatisfacaoGeral  IndiceDeBurnout^2  \\\n",
            "0                                 14.000000               36.0   \n",
            "1                                 30.000000               25.0   \n",
            "2                                  0.000000               25.0   \n",
            "3                                 26.666667               25.0   \n",
            "4                                  4.666667               25.0   \n",
            "\n",
            "   IndiceDeBurnout_X_IndiceDeSatisfacaoGeral  IndiceDeSatisfacaoGeral^2  \n",
            "0                                  14.000000                   5.444444  \n",
            "1                                  15.000000                   9.000000  \n",
            "2                                  15.000000                   9.000000  \n",
            "3                                  16.666667                  11.111111  \n",
            "4                                  11.666667                   5.444444  \n",
            "\n",
            "--- Gerando Features com Target Encoding ---\n",
            "Novas Features com Target Encoding (amostra):\n",
            "   JobRole_TargetEncoded  EducationField_TargetEncoded  \\\n",
            "0               0.174847                      0.146865   \n",
            "1               0.160959                      0.146865   \n",
            "2               0.239382                      0.134201   \n",
            "3               0.160959                      0.146865   \n",
            "4               0.239382                      0.135776   \n",
            "\n",
            "   MaritalStatus_TargetEncoded  Department_TargetEncoded  \n",
            "0                     0.255319                  0.206278  \n",
            "1                     0.124814                  0.138398  \n",
            "2                     0.255319                  0.138398  \n",
            "3                     0.124814                  0.138398  \n",
            "4                     0.124814                  0.138398  \n",
            "\n",
            "--- Consolidando e Selecionando as 10 Features Finais ---\n",
            "\n",
            "DataFrame Final com as 10 Features Avançadas Selecionadas:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1470 entries, 0 to 1469\n",
            "Data columns (total 10 columns):\n",
            " #   Column                                     Non-Null Count  Dtype  \n",
            "---  ------                                     --------------  -----  \n",
            " 0   JobRole_TargetEncoded                      1470 non-null   float64\n",
            " 1   MaritalStatus_TargetEncoded                1470 non-null   float64\n",
            " 2   EducationField_TargetEncoded               1470 non-null   float64\n",
            " 3   IndiceDeBurnout^2                          1470 non-null   float64\n",
            " 4   MonthlyIncome^2                            1470 non-null   float64\n",
            " 5   MonthlyIncome_X_IndiceDeBurnout            1470 non-null   float64\n",
            " 6   YearsAtCompany_X_IndiceDeBurnout           1470 non-null   float64\n",
            " 7   MonthlyIncome_X_IndiceDeSatisfacaoGeral    1470 non-null   float64\n",
            " 8   YearsAtCompany_X_IndiceDeSatisfacaoGeral   1470 non-null   float64\n",
            " 9   IndiceDeBurnout_X_IndiceDeSatisfacaoGeral  1470 non-null   float64\n",
            "dtypes: float64(10)\n",
            "memory usage: 115.0 KB\n",
            "\n",
            "Amostra das 10 Features Finais:\n",
            "   JobRole_TargetEncoded  MaritalStatus_TargetEncoded  \\\n",
            "0               0.174847                     0.255319   \n",
            "1               0.160959                     0.124814   \n",
            "2               0.239382                     0.255319   \n",
            "3               0.160959                     0.124814   \n",
            "4               0.239382                     0.124814   \n",
            "\n",
            "   EducationField_TargetEncoded  IndiceDeBurnout^2  MonthlyIncome^2  \\\n",
            "0                      0.146865               36.0       35916049.0   \n",
            "1                      0.146865               25.0       26316900.0   \n",
            "2                      0.134201               25.0        4368100.0   \n",
            "3                      0.146865               25.0        8462281.0   \n",
            "4                      0.135776               25.0       12027024.0   \n",
            "\n",
            "   MonthlyIncome_X_IndiceDeBurnout  YearsAtCompany_X_IndiceDeBurnout  \\\n",
            "0                          35958.0                              36.0   \n",
            "1                          25650.0                              50.0   \n",
            "2                          10450.0                               0.0   \n",
            "3                          14545.0                              40.0   \n",
            "4                          17340.0                              10.0   \n",
            "\n",
            "   MonthlyIncome_X_IndiceDeSatisfacaoGeral  \\\n",
            "0                             13983.666667   \n",
            "1                             15390.000000   \n",
            "2                              6270.000000   \n",
            "3                              9696.666667   \n",
            "4                              8092.000000   \n",
            "\n",
            "   YearsAtCompany_X_IndiceDeSatisfacaoGeral  \\\n",
            "0                                 14.000000   \n",
            "1                                 30.000000   \n",
            "2                                  0.000000   \n",
            "3                                 26.666667   \n",
            "4                                  4.666667   \n",
            "\n",
            "   IndiceDeBurnout_X_IndiceDeSatisfacaoGeral  \n",
            "0                                  14.000000  \n",
            "1                                  15.000000  \n",
            "2                                  15.000000  \n",
            "3                                  16.666667  \n",
            "4                                  11.666667  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Justificativas e Impactos das 10 Features Avançadas\n",
        "Grupo 1: Features de Target Encoding\n",
        "Estas features convertem categorias de texto em um número que representa o risco de turnover associado àquela categoria.\n",
        "\n",
        "1. JobRole_TargetEncoded (Cargo Codificado pelo Alvo)\n",
        "\n",
        "Justificativa Técnica: A variável JobRole é categórica e possui muitas classes (alta cardinalidade). O Target Encoding a transforma em uma única variável numérica, onde o valor de cada cargo é diretamente proporcional à sua taxa de turnover. Isso cria um sinal forte e monotônico para o modelo.\n",
        "\n",
        "\n",
        "Justificativa de Negócio e Impacto Esperado: A análise exploratória mostrou que cargos como \"Representante de Vendas\" e \"Técnico de Laboratório\" têm maior propensão ao turnover.\n",
        "\n",
        "Impacto Esperado: O modelo aprenderá a atribuir um peso de risco maior a funcionários nesses cargos específicos, permitindo que o RH foque ações de retenção em funções mais vulneráveis.\n",
        "\n",
        "2. MaritalStatus_TargetEncoded (Estado Civil Codificado pelo Alvo)\n",
        "\n",
        "Justificativa Técnica: Converte a variável demográfica MaritalStatus em um valor numérico que reflete o risco. É mais eficiente que One-Hot Encoding e captura a ordem de risco (se houver) entre as categorias.\n",
        "\n",
        "\n",
        "Justificativa de Negócio e Impacto Esperado: Foi observado que a proporção de solteiros no grupo de turnover é 50% maior. Isso sugere que podem ter menor vínculo com a empresa.\n",
        "\n",
        "Impacto Esperado: O modelo poderá identificar perfis demográficos que, estatisticamente, possuem maior mobilidade no mercado de trabalho e menor barreira para mudar de emprego.\n",
        "\n",
        "3. EducationField_TargetEncoded (Área de Formação Codificada pelo Alvo)\n",
        "\n",
        "Justificativa Técnica: Similar às anteriores, resume o risco associado a cada campo de educação em um único número, simplificando a complexidade para o modelo.\n",
        "\n",
        "\n",
        "Justificativa de Negócio e Impacto Esperado: As áreas de Marketing, Técnico de TI e RH apresentaram maior atrito.\n",
        "\n",
        "Impacto Esperado: Esta feature permite que o modelo identifique se a formação do colaborador pertence a uma área com alta demanda no mercado ou com desafios internos específicos na empresa, ajustando o risco de saída.\n",
        "\n",
        "Grupo 2: Features de Potência (Não-Linearidade)\n",
        "Estas features ajudam o modelo a capturar relações onde o efeito de uma variável se acelera.\n",
        "\n",
        "4. IndiceDeBurnout^2 (Índice de Burnout ao Quadrado)\n",
        "\n",
        "Justificativa Técnica: A relação entre o burnout e a decisão de sair provavelmente não é linear. O termo quadrático permite ao modelo capturar um efeito acelerado, onde um aumento de 1 ponto no índice de burnout em níveis já altos tem um impacto muito maior do que em níveis baixos.\n",
        "\n",
        "Justificativa de Negócio e Impacto Esperado: Um funcionário com burnout \"nível 8\" não tem apenas o dobro do risco de um com \"nível 4\"; o risco pode ser exponencialmente maior. Impacto Esperado: O modelo se tornará mais sensível para identificar funcionários que ultrapassaram um \"ponto de inflexão\" crítico, sinalizando uma necessidade de intervenção urgente.\n",
        "\n",
        "5. MonthlyIncome^2 (Salário Mensal ao Quadrado)\n",
        "\n",
        "Justificativa Técnica: Ajuda a modelar o efeito não-linear do salário. O impacto de um aumento de R1.000\n",
        "e\n",
        "ˊ\n",
        " muitomaiorparaquemganhaR2.000 do que para quem ganha R$15.000.\n",
        "\n",
        "\n",
        "Justificativa de Negócio e Impacto Esperado: A análise mostrou que salários baixos são um forte motivador para a saída.\n",
        "\n",
        "Impacto Esperado: O modelo poderá entender melhor a \"utilidade marginal decrescente\" do salário, ou seja, que a insatisfação com a remuneração é muito mais acentuada nas faixas salariais mais baixas.\n",
        "\n",
        "Grupo 3: Features de Interação (Efeitos Combinados)\n",
        "Estas são as features mais sofisticadas, pois medem como o efeito de uma variável muda na presença de outra.\n",
        "\n",
        "6. MonthlyIncome_X_IndiceDeBurnout (Interação Salário vs. Burnout)\n",
        "\n",
        "Justificativa Técnica: Cria uma variável que representa o efeito combinado do salário e do esgotamento.\n",
        "\n",
        "Justificativa de Negócio e Impacto Esperado: Estar sobrecarregado é ruim. Estar sobrecarregado e se sentir mal pago é uma combinação explosiva. Impacto Esperado: O modelo poderá identificar com altíssima precisão o perfil de funcionário em maior risco: aquele que sente que seu esforço (burnout) não é recompensado financeiramente.\n",
        "\n",
        "7. YearsAtCompany_X_IndiceDeBurnout (Interação Tempo de Casa vs. Burnout)\n",
        "\n",
        "Justificativa Técnica: Testa se o impacto do burnout depende do tempo de casa do funcionário.\n",
        "\n",
        "Justificativa de Negócio e Impacto Esperado: Um funcionário novo com alto burnout pode desistir rapidamente. Um funcionário antigo com alto burnout pode estar em seu limite final após anos de dedicação. Impacto Esperado: Ajuda o modelo a diferenciar o risco, permitindo ações distintas: para o novo, uma integração melhor; para o antigo, talvez uma reavaliação de carreira ou cargo.\n",
        "\n",
        "8. MonthlyIncome_X_IndiceDeSatisfacaoGeral (Interação Salário vs. Satisfação)\n",
        "\n",
        "Justificativa Técnica: Mede se o dinheiro pode \"compensar\" uma baixa satisfação geral com o ambiente e as relações.\n",
        "\n",
        "Justificativa de Negócio e Impacto Esperado: Um funcionário com alta satisfação talvez tolere um salário menor. Um funcionário insatisfeito talvez não seja retido nem com um salário alto. Impacto Esperado: Permite ao modelo avaliar se as estratégias de retenção devem focar em remuneração ou em melhorias no ambiente, dependendo do perfil do funcionário.\n",
        "\n",
        "9. YearsAtCompany_X_IndiceDeSatisfacaoGeral (Interação Tempo de Casa vs. Satisfação)\n",
        "\n",
        "Justificativa Técnica: Avalia como a \"paciência\" com a insatisfação muda ao longo do tempo.\n",
        "\n",
        "\n",
        "Justificativa de Negócio e Impacto Esperado: A fase de 3 a 5 anos é crítica. Estar insatisfeito após 5 anos pode ser um sinal de \"promessas não cumpridas\" e um preditor de saída mais forte do que a insatisfação no primeiro ano.\n",
        "\n",
        "Impacto Esperado: O modelo poderá dar mais peso à insatisfação de funcionários mais antigos, que já deram tempo para a empresa \"provar seu valor\".\n",
        "\n",
        "10. IndiceDeBurnout_X_IndiceDeSatisfacaoGeral (Interação Burnout vs. Satisfação Geral)\n",
        "\n",
        "Justificativa Técnica: Testa a interação entre o esgotamento individual (ligado ao trabalho) e a satisfação com o ambiente (ligado ao contexto social e físico).\n",
        "\n",
        "Justificativa de Negócio e Impacto Esperado: Um funcionário pode estar sobrecarregado, mas se ele gosta de seus colegas e do ambiente, isso pode funcionar como um fator de proteção.\n",
        "\n",
        "Impacto Esperado: O modelo poderá identificar se um ambiente de trabalho positivo e boas relações interpessoais  são capazes de mitigar o risco de burnout, informando ao RH que investir em cultura pode ser um \"antídoto\" eficaz\n"
      ],
      "metadata": {
        "id": "Rot4gGNZvtLr"
      }
    }
  ]
}
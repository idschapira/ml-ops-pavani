import streamlit as st
import pandas as pd
import joblib
import plotly.express as px
import shap
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score
import os

# ==============================================================================
# CONFIGURA√á√ÉO DA P√ÅGINA
# ==============================================================================
st.set_page_config(
    page_title="Dashboard Preditivo de Attrition",
    page_icon="üöÄ",
    layout="wide"
)

# ==============================================================================
# CAMINHOS E FUN√á√ïES DE CARREGAMENTO (com cache para performance)
# ==============================================================================
# Define o caminho base como o diret√≥rio onde o script est√° localizado
BASE_PATH = os.path.dirname(__file__)

# Cria os caminhos completos para cada arquivo
MODEL_PATH = os.path.join(BASE_PATH, 'modelo_campeao_xgb.pkl')
DATA_PATH = os.path.join(BASE_PATH, 'dataset_dashboard.csv')
X_TEST_PATH = os.path.join(BASE_PATH, 'X_test.pkl')
Y_TEST_PATH = os.path.join(BASE_PATH, 'y_test.pkl')
SHAP_VALUES_PATH = os.path.join(BASE_PATH, 'shap_values.pkl')

@st.cache_resource
def load_model():
    return joblib.load(MODEL_PATH)

@st.cache_data
def load_data():
    return pd.read_csv(DATA_PATH)

@st.cache_data
def load_test_data():
    X_test = joblib.load(X_TEST_PATH)
    y_test = joblib.load(Y_TEST_PATH)
    return X_test, y_test

@st.cache_resource
def load_shap_values():
    return joblib.load(SHAP_VALUES_PATH)

@st.cache_data
def get_fx_min_max(_shap_values):
    fx_values = _shap_values.base_values + _shap_values.values.sum(axis=1)
    return fx_values.min(), fx_values.max()

# Carregar todos os artefatos
try:
    modelo = load_model()
    df = load_data()
    X_test, y_test = load_test_data()
    shap_values = load_shap_values()
    fx_min, fx_max = get_fx_min_max(shap_values)
except FileNotFoundError as e:
    st.error(f"Erro ao carregar arquivos: {e}")
    st.info("Verifique se os nomes dos arquivos est√£o corretos e se eles foram enviados para o GitHub.")
    st.stop()

# ==============================================================================
# BARRA LATERAL (SIDEBAR)
# ==============================================================================
st.sidebar.title("Navega√ß√£o")
st.sidebar.markdown("Use o menu abaixo para explorar as diferentes an√°lises.")

pagina_selecionada = st.sidebar.radio("Selecione uma An√°lise", 
    ["Vis√£o Geral e KPIs", "An√°lise do Modelo Preditivo", "An√°lise de Cen√°rios (Threshold)", "An√°lise de Risco Individual"]
)

st.sidebar.title("Filtros Gerais")
depto_selecionado = st.sidebar.selectbox(
    "Filtre por Departamento",
    options=['Todos'] + sorted(df['Department'].unique().tolist())
)

if depto_selecionado != 'Todos':
    df_filtrado = df[df['Department'] == depto_selecionado].copy()
else:
    df_filtrado = df.copy()


# ==============================================================================
# L√ìGICA DE EXIBI√á√ÉO DAS P√ÅGINAS (CADA IF/ELIF TEM SEU PR√ìPRIO T√çTULO)
# ==============================================================================

if pagina_selecionada == "Vis√£o Geral e KPIs":
    st.title("üìä Vis√£o Geral do Attrition")
    st.markdown(f"Analisando o departamento: **{depto_selecionado}**")
    
    col1, col2, col3 = st.columns(3)
    total_attrition = df_filtrado[df_filtrado['Attrition'] == 'Yes'].shape[0]
    taxa_attrition = (total_attrition / df_filtrado.shape[0]) * 100 if df_filtrado.shape[0] > 0 else 0
    col1.metric("Total de Funcion√°rios", df_filtrado.shape[0])
    col2.metric("Total de Casos de Attrition", total_attrition)
    col3.metric("Taxa de Attrition (%)", f"{taxa_attrition:.2f}%")
    
    st.header("Distribui√ß√£o de Attrition")
    if not df_filtrado.empty:
        col_graf1, col_graf2 = st.columns(2)
        with col_graf1:
            fig_job_role = px.histogram(df_filtrado, x='JobRole', color='Attrition', barmode='group', title="Attrition por Cargo").update_xaxes(categoryorder="total descending")
            st.plotly_chart(fig_job_role, use_container_width=True)
        with col_graf2:
            fig_marital = px.pie(df_filtrado[df_filtrado['Attrition']=='Yes'], names='MaritalStatus', title="Perfil de Attrition por Estado Civil")
            st.plotly_chart(fig_marital, use_container_width=True)
            
    st.header("Dados Detalhados")
    st.dataframe(df_filtrado)

elif pagina_selecionada == "An√°lise do Modelo Preditivo":
    st.title("üîç An√°lise do Modelo Preditivo (XGBoost Otimizado)")
    
    st.header("Import√¢ncia das Features (Feature Importance)")
    st.markdown("Quais vari√°veis o modelo considera mais importantes para prever o turnover?")
    feature_importance = pd.DataFrame({'feature': X_test.columns, 'importance': modelo.feature_importances_}).sort_values('importance', ascending=False)
    fig_importance = px.bar(feature_importance.head(15), x='importance', y='feature', orientation='h', title="Top 15 Features Mais Importantes")
    st.plotly_chart(fig_importance, use_container_width=True)
    
    st.header("Interpretabilidade com SHAP")
    st.markdown("Como cada vari√°vel impacta a decis√£o do modelo? O gr√°fico abaixo mostra o impacto m√©dio de cada feature.")
    fig, ax = plt.subplots()
    shap.summary_plot(shap_values, X_test, plot_type="bar", show=False)
    st.pyplot(fig)
    
    st.header("Matriz de Confus√£o")
    st.markdown("Como o modelo performou no conjunto de teste? A matriz mostra os acertos e erros.")
    y_pred = modelo.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Ficou', 'Saiu'])
    fig, ax = plt.subplots(figsize=(6, 4))
    disp.plot(ax=ax, cmap='Blues', values_format='d')
    st.pyplot(fig)

elif pagina_selecionada == "An√°lise de Cen√°rios (Threshold)":
    st.title("‚öôÔ∏è Simulador de Threshold de Decis√£o")
    st.markdown("O modelo gera uma probabilidade de sa√≠da para cada funcion√°rio. O 'threshold' √© o ponto de corte (padr√£o 0.5) para classificar algu√©m como 'alto risco'. Ajuste o threshold para ver o impacto no n√∫mero de funcion√°rios sinalizados e na performance do modelo.")
    
    y_probs = modelo.predict_proba(X_test)[:, 1]
    
    threshold = st.slider(
        "Selecione o Threshold de Risco",
        min_value=0.0,
        max_value=1.0,
        value=0.5,
        step=0.01
    )
    
    y_pred_custom = (y_probs >= threshold).astype(int)
    
    st.header(f"Resultados com Threshold de {threshold:.2f}")
    
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Funcion√°rios Sinalizados", f"{sum(y_pred_custom)}")
    col2.metric("Recall", f"{recall_score(y_test, y_pred_custom):.2f}")
    col3.metric("Precision", f"{precision_score(y_test, y_pred_custom, zero_division=0):.2f}")
    col4.metric("F1-Score", f"{f1_score(y_test, y_pred_custom, zero_division=0):.2f}")
    
    st.markdown("---")
    st.markdown("**Recall:** Dos funcion√°rios que **realmente sa√≠ram**, qual porcentagem o modelo conseguiu capturar?")
    st.markdown("**Precision:** Dos funcion√°rios que o modelo **sinalizou como risco**, qual porcentagem realmente saiu?")

elif pagina_selecionada == "An√°lise de Risco Individual":
    st.title("üë§ An√°lise de Risco Individual")
    st.markdown("Selecione um funcion√°rio (pelo seu ID) para ver a previs√£o do modelo e a explica√ß√£o detalhada do porqu√™ dessa previs√£o.")
    
    employee_numbers_disponiveis = df.loc[X_test.index, 'EmployeeNumber']
    
    id_selecionado = st.selectbox(
        "Selecione o EmployeeNumber do Funcion√°rio",
        options=employee_numbers_disponiveis.values
    )
    
    if id_selecionado is not None:
        idx_selecionado = employee_numbers_disponiveis[employee_numbers_disponiveis == id_selecionado].index[0]
        
        st.header(f"Analisando Funcion√°rio (ID: {id_selecionado})")
        
        probabilidade = modelo.predict_proba(X_test.loc[[idx_selecionado]])[0, 1]
        
        st.metric("Probabilidade de Sa√≠da", f"{probabilidade:.2%}")
        
        st.markdown("---")
        st.subheader("Explica√ß√£o da Previs√£o (SHAP Waterfall Plot)")
        st.markdown("O gr√°fico abaixo mostra como cada caracter√≠stica do funcion√°rio contribuiu para a pontua√ß√£o final de risco.")
        
        shap_index = X_test.index.get_loc(idx_selecionado)
        
        shap_explanation_individual = shap.Explanation(
            values=shap_values.values[shap_index],
            base_values=shap_values.base_values[shap_index],
            data=X_test.loc[idx_selecionado],
            feature_names=X_test.columns.tolist()
        )
        
        fig, ax = plt.subplots(figsize=(10, 6))
        shap.plots.waterfall(shap_explanation_individual, max_display=15, show=False)
        plt.tight_layout()
        st.pyplot(fig)
        
        with st.expander("Como interpretar este gr√°fico?"):
            st.markdown(f"""
            Este gr√°fico de cascata (Waterfall Plot) mostra como a previs√£o de risco √© constru√≠da passo a passo:

            - **E[f(x)] (Valor Base):** √â o risco m√©dio de sa√≠da para todos os funcion√°rios.
            - **Barras Vermelhas:** Representam as caracter√≠sticas que **aumentam** o risco de sa√≠da.
            - **Barras Azuis:** Representam as caracter√≠sticas que **diminuem** o risco (fatores de prote√ß√£o).
            - **f(x) (Valor Final):** √â a pontua√ß√£o final de risco. Para refer√™ncia, as pontua√ß√µes no nosso teste variaram de **{fx_min:.2f}** (risco mais baixo) a **{fx_max:.2f}** (risco mais alto).
            """)
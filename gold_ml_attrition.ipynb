{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "14YOoQyYXnuyn3nO0wt8Wh6jKZiILLx8K",
      "authorship_tag": "ABX9TyPpZtVOtBLJr40omG8gvGfI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rchavarria3007/ml-ops-pavani/blob/main/gold_ml_attrition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3z9exDMRjBJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# Setup e Carregamento de Dados\n",
        "# ==============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import PolynomialFeatures, LabelEncoder\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# Configuração para exibir todas as colunas do pandas\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Carregamento do dataset\n",
        "try:\n",
        "    file_name = \"/content/drive/MyDrive/dev/datascienceexp/sv_hr_final_features_v1.csv\"\n",
        "    sv_hr_features = pd.read_csv(file_name)\n",
        "    print(f\"\\nDataset '{file_name}' carregado com sucesso!\")\n",
        "    print(\"Dimensões do dataset:\", sv_hr_features.head())\n",
        "except StopIteration:\n",
        "    print(\"\\nNenhum arquivo foi enviado.\")\n",
        "    sv_hr_features = None\n",
        "except Exception as e:\n",
        "    print(f\"Ocorreu um erro ao carregar o arquivo: {e}\")\n",
        "    sv_hr_features = None\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i37H1c0VR7_E",
        "outputId": "c2317f1c-e2f4-4b39-e665-373fa557e2eb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset '/content/drive/MyDrive/dev/datascienceexp/sv_hr_final_features_v1.csv' carregado com sucesso!\n",
            "Dimensões do dataset:    MaritalStatus_TargetEncoded  IndiceDeBurnout^2  MonthlyIncome^2  \\\n",
            "0                     0.255319               36.0       35916049.0   \n",
            "1                     0.124814               25.0       26316900.0   \n",
            "2                     0.255319               25.0        4368100.0   \n",
            "3                     0.124814               25.0        8462281.0   \n",
            "4                     0.124814               25.0       12027024.0   \n",
            "\n",
            "   MonthlyIncome_X_IndiceDeBurnout  YearsAtCompany_X_IndiceDeBurnout  \\\n",
            "0                          35958.0                              36.0   \n",
            "1                          25650.0                              50.0   \n",
            "2                          10450.0                               0.0   \n",
            "3                          14545.0                              40.0   \n",
            "4                          17340.0                              10.0   \n",
            "\n",
            "   MonthlyIncome_X_IndiceDeSatisfacaoGeral  \\\n",
            "0                             13983.666667   \n",
            "1                             15390.000000   \n",
            "2                              6270.000000   \n",
            "3                              9696.666667   \n",
            "4                              8092.000000   \n",
            "\n",
            "   YearsAtCompany_X_IndiceDeSatisfacaoGeral  \\\n",
            "0                                 14.000000   \n",
            "1                                 30.000000   \n",
            "2                                  0.000000   \n",
            "3                                 26.666667   \n",
            "4                                  4.666667   \n",
            "\n",
            "   IndiceDeBurnout_X_IndiceDeSatisfacaoGeral  Attrition_encoded  \n",
            "0                                  14.000000                  1  \n",
            "1                                  15.000000                  0  \n",
            "2                                  15.000000                  1  \n",
            "3                                  16.666667                  0  \n",
            "4                                  11.666667                  0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns # Para visualizações mais agradáveis\n",
        "\n",
        "# Mapear 'Yes'/'No' para 1/0 para a variável alvo\n",
        "df['label'] = df['Attrition'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "final_10_features_list = [\n",
        "    # Target Encodings\n",
        "    'MaritalStatus_TargetEncoded',\n",
        "    # Potências\n",
        "    'IndiceDeBurnout^2',\n",
        "    'MonthlyIncome^2',\n",
        "    # Interações\n",
        "    'MonthlyIncome_X_IndiceDeBurnout',\n",
        "    'YearsAtCompany_X_IndiceDeBurnout',\n",
        "    'MonthlyIncome_X_IndiceDeSatisfacaoGeral',\n",
        "    'YearsAtCompany_X_IndiceDeSatisfacaoGeral',\n",
        "    'IndiceDeBurnout_X_IndiceDeSatisfacaoGeral',\n",
        "    ]\n",
        "\n",
        "#\n",
        "\n",
        "# Separar features (X) e target (y)\n",
        "X = sv_hr_features[final_10_features_list]\n",
        "y = sv_hr_features['Attrition_encoded']\n",
        "\n",
        "# --- 2. Dividir os dados em treino e teste ---\n",
        "# stratify=y é crucial para problemas de classes desbalanceadas como turnover\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "\n",
        "# --- 3. Criar transformadores para pré-processamento ---\n",
        "# ColumnTransformer aplica diferentes transformações a diferentes colunas\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features), # Escalonamento para features numéricas\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features) # One-hot encoding para features categóricas\n",
        "    ])\n",
        "\n",
        "# --- 4. Construir o Pipeline com pré-processamento e o modelo de Regressão Logística ---\n",
        "# O Pipeline encadeia as etapas de processamento e o modelo\n",
        "model_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(solver='liblinear', random_state=42)) # 'liblinear' é um bom solver para datasets menores/médios e é robusto\n",
        "])\n",
        "\n",
        "# --- 5. Treinar o modelo ---\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# --- 6. Fazer previsões no conjunto de teste ---\n",
        "# Probabilidades da classe positiva (Attrition = Yes)\n",
        "y_pred_proba = model_pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Previsões binárias (0 ou 1) usando o threshold padrão (0.5)\n",
        "y_pred = model_pipeline.predict(X_test)\n",
        "\n",
        "# --- 7. Avaliar o modelo ---\n",
        "print(\"--- Relatório de Classificação ---\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\n--- AUC (Area Under the ROC Curve) ---\")\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f\"AUC: {auc:.4f}\")\n",
        "\n",
        "# Exemplo de como visualizar as probabilidades para alguns funcionários de teste\n",
        "print(\"\\n--- Probabilidades de Attrition para Dados de Teste (Amostra) ---\")\n",
        "# Criar um DataFrame com as previsões para facilitar a visualização\n",
        "# Recriamos o índice para que ele combine com o y_test após o split\n",
        "X_test_display = X_test.copy()\n",
        "X_test_display['True_Attrition'] = y_test.values # .values para garantir o alinhamento\n",
        "X_test_display['Predicted_Attrition_Prob'] = y_pred_proba\n",
        "X_test_display['Predicted_Attrition'] = y_pred\n",
        "\n",
        "# Ordenar por probabilidade para ver os de \"alta chance\"\n",
        "results_df_sorted = X_test_display.sort_values(by='Predicted_Attrition_Prob', ascending=False)\n",
        "print(results_df_sorted.head(5).to_string()) # Mostrar os 5 com maior probabilidade\n",
        "\n",
        "# --- Visualizações Adicionais (Recomendadas para o MBA) ---\n",
        "\n",
        "# Distribuição das Probabilidades\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(y_pred_proba[y_test == 0], color='blue', label='No Attrition', kde=True, stat='density', alpha=0.5)\n",
        "sns.histplot(y_pred_proba[y_test == 1], color='red', label='Attrition', kde=True, stat='density', alpha=0.5)\n",
        "plt.title('Distribuição das Probabilidades de Attrition')\n",
        "plt.xlabel('Probabilidade de Attrition')\n",
        "plt.ylabel('Densidade')\n",
        "plt.legend()\n",
        "plt.grid(axis='y', alpha=0.75)\n",
        "plt.show()\n",
        "\n",
        "# Curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='orange', label=f'Curva ROC (AUC = {auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', linestyle='--', label='Classificador Aleatório')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Taxa de Falsos Positivos (FPR)')\n",
        "plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')\n",
        "plt.title('Curva Característica de Operação do Receptor (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Egsk995eZ5KS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler # Apenas StandardScaler é necessário no pré-processamento\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- 1. Criar um DataFrame de exemplo (Simulando o DataFrame JÁ TRANSFORMADO) ---\n",
        "# Este DataFrame 'df' abaixo é um EXEMPLO de como seu DataFrame DEVE ESTAR\n",
        "# ANTES DESTE PASSO, com as colunas categóricas já one-hot encoded\n",
        "# (ex: 'MaritalStatus_Married', 'MaritalStatus_Single', 'MaritalStatus_Divorced')\n",
        "# e as colunas numéricas prontas para escalonamento ou uso direto.\n",
        "\n",
        "data_transformed = {\n",
        "    \"id\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
        "    # Colunas categóricas já ONE-HOT ENCODED\n",
        "    \"MaritalStatus_Single\": [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1],\n",
        "    \"MaritalStatus_Married\": [0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0],\n",
        "    \"MaritalStatus_Divorced\": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
        "    # Colunas numéricas (sem escalonamento ainda, se for aplicar StandardScaler aqui)\n",
        "    \"JobLevel\": [1, 2, 1, 3, 1, 2, 1, 2, 1, 2, 1, 2, 1, 3, 1],\n",
        "    \"JobInvolvement\": [1, 2, 1, 3, 1, 2, 1, 2, 1, 2, 1, 2, 1, 3, 1],\n",
        "    \"YearsAtCompany\": [3, 5, 2, 8, 4, 6, 1, 7, 3, 9, 5, 10, 2, 6, 4],\n",
        "    \"MonthlyIncome\": [3000, 5000, 2500, 7000, 3500, 6000, 2000, 6500, 3200, 8000, 4000, 9000, 2800, 5500, 3800],\n",
        "    \"StockOptionLevel\": [0, 1, 0, 2, 0, 1, 0, 1, 0, 1, 0, 1, 0, 2, 0],\n",
        "    \"JobSatisfaction\": [3, 4, 2, 3, 2, 4, 1, 3, 2, 4, 2, 4, 1, 3, 2],\n",
        "    \"EnvironmentSatisfaction\": [3, 4, 2, 3, 2, 4, 1, 3, 2, 4, 2, 4, 1, 3, 2],\n",
        "    \"WorkLifeBalance\": [1, 2, 1, 3, 1, 2, 1, 2, 1, 2, 1, 2, 1, 3, 1],\n",
        "    # Variável alvo (já mapeada para 0/1)\n",
        "    \"Attrition\": ['Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n",
        "    \"label\": [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1], # 'Yes'=1, 'No'=0\n",
        "}\n",
        "df = pd.DataFrame(data_transformed)\n",
        "\n",
        "\n",
        "# Definir todas as features que serão usadas no modelo\n",
        "# Incluir as novas colunas one-hot encoded E as colunas numéricas\n",
        "features_for_model = [\n",
        "    \"MaritalStatus_Single\", \"MaritalStatus_Married\", \"MaritalStatus_Divorced\", # Exemplo de features categóricas já transformadas\n",
        "    'JobLevel', 'JobInvolvement', 'YearsAtCompany', 'MonthlyIncome',\n",
        "    'StockOptionLevel', 'JobSatisfaction', 'EnvironmentSatisfaction', 'WorkLifeBalance'\n",
        "]\n",
        "\n",
        "# Separar features (X) e target (y)\n",
        "X = df[features_for_model]\n",
        "y = df['label']\n",
        "\n",
        "# --- 2. Dividir os dados em treino e teste ---\n",
        "# stratify=y é crucial para problemas de classes desbalanceadas como turnover\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "\n",
        "# --- 3. (AJUSTADO) Pipelines para processamento de features e modelo ---\n",
        "# Se as colunas categóricas já estão ONE-HOT ENCODED,\n",
        "# então só precisamos de StandardScaler para as features numéricas\n",
        "# e depois passar tudo para a Regressão Logística.\n",
        "\n",
        "# Identifique as features numéricas DENTRE AS features_for_model\n",
        "# que ainda precisam de StandardScaler.\n",
        "# Assumimos que as colunas 'MaritalStatus_...' são binárias e não precisam de StandardScaler.\n",
        "numerical_features_to_scale = [\n",
        "    'JobLevel', 'JobInvolvement', 'YearsAtCompany', 'MonthlyIncome',\n",
        "    'StockOptionLevel', 'JobSatisfaction', 'EnvironmentSatisfaction', 'WorkLifeBalance'\n",
        "]\n",
        "\n",
        "# Crie um pipeline de pré-processamento para escalar apenas as colunas numéricas\n",
        "# Usamos ColumnTransformer novamente, mas agora apenas para StandardScaler\n",
        "preprocessor_final = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler()) # Aplica StandardScaler a todas as colunas que chegam aqui\n",
        "])\n",
        "\n",
        "# Identificar as colunas que NÃO serão escaladas pelo StandardScaler no preprocessor_final.\n",
        "# Ou seja, as colunas one-hot encoded já numéricas.\n",
        "# Para isso, precisamos que o preprocessor_final saiba quais colunas escalar e quais passar.\n",
        "# Uma forma mais robusta é usar ColumnTransformer com um 'passthrough' para as outras colunas.\n",
        "\n",
        "# Se todas as 'features_for_model' precisam ser escaladas (se todas forem numéricas e de mesma ordem de grandeza),\n",
        "# você pode simplificar para:\n",
        "# model_pipeline = Pipeline(steps=[\n",
        "#     ('scaler', StandardScaler()),\n",
        "#     ('classifier', LogisticRegression(solver='liblinear', random_state=42))\n",
        "# ])\n",
        "# Mas como você tem as colunas one-hot encoded, é melhor usar ColumnTransformer com passthrough.\n",
        "\n",
        "\n",
        "# Alternativa com ColumnTransformer para escalar APENAS as colunas numéricas\n",
        "# e passar as one-hot encoded sem transformação\n",
        "preprocessor_for_pipeline = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num_scaler', StandardScaler(), numerical_features_to_scale),\n",
        "        ('passthrough', 'passthrough', [col for col in features_for_model if col not in numerical_features_to_scale])\n",
        "    ],\n",
        "    remainder='passthrough' # Isso é útil se houver outras colunas que você não listou e quer que passem direto\n",
        ")\n",
        "\n",
        "\n",
        "# --- 4. (AJUSTADO) Construir o Pipeline com pré-processamento e o modelo ---\n",
        "model_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor_for_pipeline), # Inclui o escalonamento e o passthrough\n",
        "    ('classifier', LogisticRegression(solver='liblinear', random_state=42))\n",
        "])\n",
        "\n",
        "# --- 5. Treinar o modelo ---\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# --- 6. Fazer previsões no conjunto de teste ---\n",
        "y_pred_proba = model_pipeline.predict_proba(X_test)[:, 1]\n",
        "y_pred = model_pipeline.predict(X_test)\n",
        "\n",
        "# --- 7. Avaliar o modelo ---\n",
        "print(\"--- Relatório de Classificação ---\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\n--- AUC (Area Under the ROC Curve) ---\")\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "print(f\"AUC: {auc:.4f}\")\n",
        "\n",
        "# Exemplo de como visualizar as probabilidades para alguns funcionários de teste\n",
        "print(\"\\n--- Probabilidades de Attrition para Dados de Teste (Amostra) ---\")\n",
        "X_test_display = X_test.copy()\n",
        "X_test_display['True_Attrition'] = y_test.values\n",
        "X_test_display['Predicted_Attrition_Prob'] = y_pred_proba\n",
        "X_test_display['Predicted_Attrition'] = y_pred\n",
        "\n",
        "results_df_sorted = X_test_display.sort_values(by='Predicted_Attrition_Prob', ascending=False)\n",
        "print(results_df_sorted.head(5).to_string())\n",
        "\n",
        "# --- Visualizações Adicionais ---\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(y_pred_proba[y_test == 0], color='blue', label='No Attrition', kde=True, stat='density', alpha=0.5)\n",
        "sns.histplot(y_pred_proba[y_test == 1], color='red', label='Attrition', kde=True, stat='density', alpha=0.5)\n",
        "plt.title('Distribuição das Probabilidades de Attrition')\n",
        "plt.xlabel('Probabilidade de Attrition')\n",
        "plt.ylabel('Densidade')\n",
        "plt.legend()\n",
        "plt.grid(axis='y', alpha=0.75)\n",
        "plt.show()\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='orange', label=f'Curva ROC (AUC = {auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', linestyle='--', label='Classificador Aleatório')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Taxa de Falsos Positivos (FPR)')\n",
        "plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')\n",
        "plt.title('Curva Característica de Operação do Receptor (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QniLqvEGgmPk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}